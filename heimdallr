#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import re
import sys
import time
import atexit
import signal
import argparse
import tempfile
import subprocess
import datetime as dt
from abc import ABC, abstractmethod
from contextlib import contextmanager, suppress
from csv import DictWriter
from datetime import datetime
from typing import Dict, Iterable, List


LOCAL_TIMEZONE = datetime.now(dt.timezone.utc).astimezone().tzinfo


def to_local_str(date: datetime):
    """Convert a datetime into a string with local timezone."""
    return date.replace(tzinfo=LOCAL_TIMEZONE).strftime('%Y-%m-%dT%H:%M:%S%Z')


class Resource(ABC):
    """Represents an abstract system resource that should be monitored.

    All resources need to define the output file where the CSV will be saved.

    """
    def __init__(self, output_file):
        self._output_file = output_file

    @abstractmethod
    def fetch_data(self, config) -> Iterable[Dict[str, object]]:
        """Fetch the data for the resource.

        This method should return an iterable that yields dict items containing the data to save to the CSV file.
        Each dict will be written in a separate row, in the order in which they are yielded.

        """
        raise NotImplementedError

    @property
    @abstractmethod
    def column_names(self) -> List[str]:
        """Return the list of column names."""

    def monitor(self, config, header=True):
        """Monitors the resource.

        This method should NOT be overridden by subclasses. All the logic for fetching, parsing and combining data
        should be done inside the `fetch_data` method.

        """
        with open(self._output_file, 'a') as out_file:
            writer = DictWriter(out_file, self.column_names)
            if header:
                writer.writeheader()
            for data_row in self.fetch_data(config):
                writer.writerow(data_row)


class NullResource(Resource):
    """A null resource. This is use as a placeholder when no resource is given."""
    def __init__(self):
        super().__init__(None)

    def fetch_data(self, config) -> Iterable[Dict[str, object]]:
        """Returns an empty iterable."""
        return []

    @property
    def column_names(self) -> List[str]:
        """No columns are defined"""
        return []

    def monitor(self, config, header=True):
        """Does nothing."""
        return


class SimpleCommandResource(Resource):
    """Base class for resources that are defined by running a single command and parsing its result.

    Most resources fall into this simple category.

    Subclasses of this class must define at least two methods `make_cmdline` and `make_regex`.
    The `make_cmdline` method returns a list of strings that is used as a command line
    while `make_regex` should return a regex object that can be used to parse the output of the
    command specified.

    The regex can be used in two ways:
     - to parse the whole output using the `fullmatch` method (the default).
     - to parse "rows of data" from the output using the `finditer` method.
    To specify the latter behaviour you have to set `table_output=True`, indicating that the output of your
    command can be treated as a table and the regex is treated as a regex matching one line from that table.

    In both cases the dict object generated by `fetch_data` will be the result of `match.groupdict()` with
    the addition of the special column `datetime` which will always contain the current time.

    """
    def __init__(self, output_file, table_output=False):
        super().__init__(output_file)
        self._column_names = None
        self._table_output = table_output

    @property
    def column_names(self):
        if self._column_names is None:
            regex = self.make_regex({})
            self._column_names = ['datetime'] + sorted(regex.groupindex.keys(), key=regex.groupindex.get)
        return self._column_names

    def fetch_data(self, config):
        """Fetches the data from the command returned by `make_cmdline`.

        The `config` argument may contain the `backup_bad_output_dir` parameter.
        If specified, it should be the path to a directory in which we can
        save files containing the output of the commands run. These outputs will be created whenever parsing
        using the regex fails.
        This behaviour is useful in two instances:
         - to debug the regex during development
         - to avoid losing data in unexpected circumstances in production
        By default no output is saved.

        """
        cmdline = self.make_cmdline(config)
        result = subprocess.run(cmdline, stdout=subprocess.PIPE)
        try:
            yield from self._generic_parse(result.stdout.decode('utf-8'), config)
        except Exception:
            self._backup_output(cmdline[0], config.get('backup_bad_output_dir'), result)

    def _backup_output(self, command_name, bad_output_dir, result):
        if bad_output_dir:
            path = os.path.join(bad_output_dir, 'bad_{}_{}.txt'.format(command_name, to_local_str(datetime.now())))
            with open(path, 'wb') as bad_file:
                bad_file.write(result.stdout or b'')

    def _generic_parse(self, output, config):
        cleaned_output = self.clean_output(output, config)
        regex = self.make_regex(config)
        if self._table_output:
            info = {'datetime': to_local_str(datetime.now()), 'values': []}
            for match in regex.finditer(cleaned_output):
                res = match.groupdict()
                info['values'].append(res)
        else:
            match = regex.fullmatch(cleaned_output)
            if match:
                info = match.groupdict()
            else:
                info = dict.fromkeys(self.column_names, 'N/A')
            info['datetime'] = to_local_str(datetime.now())
        yield from self.clean_data(info, config)

    def clean_output(self, output, config):
        """This method should return clean `output` and return a string that will be matched
        with the regex.

        """
        return output

    def clean_data(self, info, config):
        """This method will be called with the result of the parsing of the output via the regex
        and should return an iterable of dicts ready to be written to the CSV file.

        """
        yield info

    @abstractmethod
    def make_cmdline(self, config):
        """Return the command line to run to fetch the data for this configuration."""

    @abstractmethod
    def make_regex(self, config):
        """Return the regex to parse the output for this configuration."""



class NvidiaGpu(SimpleCommandResource):
    """Resource associated with the `nvidia-smi` command output."""

    NVIDIA_SMI_REGEX = re.compile(
        r'''
            .*\s*
            NVIDIA-SMI\s*(?P<nvidia_smi_version>\d+\.\d+)\s*
                Driver\sVersion:\s*(?P<driver_version>\d+\.\d+)\s*
                CUDA\sVersion:\s*(?P<cuda_version>\d+\.\d+)\s*
            GPU\s*Name\s*
                Persistence-M+\s*\|\s*
                Bus-Id\s*Disp.A\s*\|\s*
                Volatile\s*Uncorr.\s*ECC\s*
            Fan\s* Temp\s* Perf\s* Pwr:Usage/Cap\|\s*
                Memory-Usage\s*\|\s*
                GPU-Util\s*Compute\s*M.\s*
            (?P<gpu_number>\d+)\s* (?P<gpu_name>[\w\s]+(?=\s+\w+\s+))\s+ (?P<persistence_m>\w+)\s* \|\s*
                (?P<bus_id>\d+:\d+:\d+\.\d+)\s* (?P<disp_a>\w+)\s*\|\s*
                (?P<ecc>\S*)\s*
            (?P<gpu_fan>\d+[%])\s* (?P<gpu_temp>\d+[C])\s* (?P<gpu_perf>\w+)\s* 
                (?P<gpu_power_usage>\d+[W])\s* / \s*(?P<gpu_power_cap>\d+[W])\s* \|\s*
                (?P<gpu_ram_usage>\d+MiB)\s*/\s*(?P<gpu_total_ram>\d+MiB)\s*\|\s*
                (?P<gpu_util>\d+[%])\s*(?P<compute_m>\w+)\s*
            Processes:\s*
            GPU\s* Memory\s* GPU\s* PID\s* Type\s* Process\s* name\s* Usage\s*
            (?P<proc_info>(?:\n|.)*)
        ''',
        flags=re.VERBOSE
    )

    def clean_output(self, output, config):
        output = re.sub(r'^[+|][+=-]+[|+]\n', '', output, flags=re.MULTILINE)
        output = re.sub(r'^\|\s*', '', output, flags=re.MULTILINE)
        output = re.sub(r'\s*\|$', '', output, flags=re.MULTILINE)
        return re.sub(r'^\s*\n', '', output, flags=re.MULTILINE)

    def clean_data(self, info, config):
        pid = str(config.get('pid')) if 'pid' in config else None
        procs = []
        for line in info['proc_info'].splitlines():
            proc_m = re.fullmatch(
                r'\s*(?P<gpu>\d+)\s*(?P<pid>\d+)\s*(?P<type>\w+)\s*(?P<name>.+)\s+(?P<mem_usage>\d+MiB)\s*',
                line
            )
            procs.append({k: v.strip() for k, v in proc_m.groupdict().items()})
        proc_order = ('pid', 'gpu', 'mem_usage', 'type', 'name')
        proc_info = '|'.join(
            ','.join(proc[k] for k in proc_order) for proc in procs if pid is None or proc['pid'] == pid
        )
        info['proc_info'] = proc_info
        yield info

    def make_cmdline(self, config):
        return ['nvidia-smi']

    def make_regex(self, config):
        return self.NVIDIA_SMI_REGEX


class CpuTemps(SimpleCommandResource):
    """Temperatures of the CPU cores"""

    SENSORS_REGEX = re.compile(
        r'''
            (?P<core>Core\s+\d+):\s*(?P<temp>[-+]?\d+\.\d+°C)\s*
            \(high\s*=\s*(?P<high_temp>[-+]?\d+\.\d+°C),\s*crit\s*=\s*(?P<crit_temp>[-+]?\d+\.\d+°C)\)
        ''',
        re.VERBOSE
    )

    def __init__(self, output_file):
        super().__init__(output_file, table_output=True)

    def clean_data(self, info, config):
        columns = ('core', 'temp', 'high_temp', 'crit_temp')
        for value in info['values']:
            row_data = {col: value[col] for col in columns}
            row_data['datetime'] = info['datetime']
            yield row_data
        if not info['values']:
            row_data = dict.fromkeys(columns, 'N/A')
            row_data['datetime'] = info['datetime']
            yield row_data

    def make_cmdline(self, config):
        return ['sensors']

    def make_regex(self, config):
        return self.SENSORS_REGEX


class CpuRam(SimpleCommandResource):
    """Usage of CPU, Ram, swap etc. Implemented by parsing the output of `top`."""

    TOP_REGEX = re.compile(
        r'''
            top\s*-\s*(?P<time>\d+:\d+:\d+)\s*
                up\s*(?P<uptime>[^,]+),\s*
                (?P<num_users>\d+)\s*users,\s*
                load\s*average:\s*(?P<load_avg_1>[\d,]+),\s*(?P<load_avg_2>[\d,]+),\s*(?P<load_avg_3>[\d,]+)\s*
            Tasks:\s*(?P<num_tasks>\d+)\s*total,\s*
                (?P<num_running_tasks>\d+)\s*running,\s*
                (?P<num_sleeping_tasks>\d+)\s*sleeping,\s*
                (?P<num_stopped_tasks>\d+)\s*stopped,\s*
                (?P<num_zombie_tasks>\d+)\s*zombie\s*
            %Cpu\(s\):\s*(?P<user_cpu>[\d,]+)\s*us,\s*
                (?P<system_cpu>[\d,]+)\s*sy,\s*
                (?P<ni_cpu>[\d,]+)\s*ni,\s*
                (?P<id_cpu>[\d,]+)\s*id,\s*
                (?P<wa_cpu>[\d,]+)\s*wa,\s*
                (?P<hi_cpu>[\d,]+)\s*hi,\s*
                (?P<si_cpu>[\d,]+)\s*si,\s*
                (?P<st_cpu>[\d,]+)\s*st\s*
            (?P<ram_unit>\w+)\s*Mem\s*:\s*
                (?P<ram_total>\d+)\s*total,\s*
                (?P<free_ram>\d+)\s*free,\s*
                (?P<used_ram>\d+)\s*used,\s*
                (?P<ram_buff_cache>\d+)\s*buff/cache\s*
            (?P<swap_unit>\w+)\s*Swap:\s*
                (?P<swap_total>\d+)\s*total,\s*
                (?P<swap_free>\d+)\s*free,\s*
                (?P<swap_used>\d+)\s*used.\s*
                (?P<avail>\d+)\s*avail\s*Mem\s*.*\s*
            (?P<proc_info>(?:.|\n)+)
        ''', re.VERBOSE
    )

    def clean_data(self, info, config):
        pid = str(config.get('pid')) if 'pid' in config else None
        procs = []
        for line in info['proc_info'].splitlines():
            proc_m = re.fullmatch(
                r'\s*(?P<pid>\S+)\s*(?P<user>\S+)\s*(?P<priority>\S+)\s*(?P<nice>\S+)\s*'
                r'(?P<virtual_mem>\S+)\s*(?P<res_mem>\S+)\s*(?P<shared_mem>\S+)\s*\S+\s*'
                r'(?P<perc_cpu>[\d,]+)\s*(?P<perc_mem>[\d,]+)\s*'
                r'(?P<uptime>\S+)\s*(?P<command>.*)\s*',
                line
            )
            procs.append(proc_m.groupdict())
        proc_order = (
            'pid', 'perc_cpu', 'perc_mem', 'uptime', 'user', 'priority', 'nice', 'virtual_mem', 'res_mem',
            'shared_mem', 'command',
        )
        proc_info = '|'.join(
            ','.join(proc[k] for k in proc_order) for proc in procs if pid is None or proc['pid'] == pid
        )
        info['proc_info'] = proc_info
        yield info

    def make_cmdline(self, config):
        return ['top', '-n', '1', '-b'] + (['-p', str(config['pid'])] if config.get('pid') is not None else [])

    def make_regex(self, config):
        return self.TOP_REGEX


def parse_interval(interval):
    """Parse a time interval into the equivalent number of seconds:

        >>> parse_interval("5s")
        5
        >>> parse_interval("2m")
        120
        >>> parse_interval("1.5h")
        5472.0

    """
    match = re.fullmatch(r'(\d+(?:\.\d+)?)([smh])', interval)
    return float(match[1]) * ({'s': 1, 'm': 60, 'h': 60 * 60}[match[2]])


def _pid_exists(pid):
    """Return True if a process with the given pid exists. False otherwise."""
    try:
        os.kill(pid, 0)
        return True
    except OSError:
        return False


def run(interval, gpu, temperatures, cpu_and_ram, pid, write_header=True, backup_bad_output_dir=None):
    """Mainloop that calls the `monitor_*` function and then sleeps for `interval` seconds."""
    default_config = {'backup_bad_output_dir': backup_bad_output_dir}
    gpu_config = dict(default_config, pid=pid)
    cpu_config = dict(pid=pid)
    temps_config = default_config.copy()

    gpu_resource = NvidiaGpu(gpu) if gpu else NullResource()
    cpu_and_ram_resource = CpuRam(cpu_and_ram) if cpu_and_ram else NullResource()
    temps_resource = CpuTemps(temperatures) if temperatures else NullResource()

    with suppress(KeyboardInterrupt):
        while pid is None or _pid_exists(pid):
            gpu_resource.monitor(gpu_config, header=write_header)
            temps_resource.monitor(temps_config, header=write_header)
            cpu_and_ram_resource.monitor(cpu_config, header=write_header)
            write_header = False
            time.sleep(interval)


def _make_parser():
    parent_parser = argparse.ArgumentParser(add_help=False)
    parent_parser.add_argument('-i', '--interval', type=parse_interval, default='30s',
                               help='Interval between measurements.\nSyntax is: \d+(\.\d+)?(s|m|h).')
    parent_parser.add_argument('-g', '--gpu', help='Monitor GPU usage', metavar='LOGFILE')
    parent_parser.add_argument('-t', '--temperatures', help='Monitor temperatures of CPU', metavar='LOGFILE')
    parent_parser.add_argument('-c', '--cpu', '--cpu-and-ram', dest='cpu_and_ram', metavar='LOGFILE',
                               help='Monitor processes, CPU & RAM usage via top')
    parent_parser.add_argument('-q', '--quiet', action='store_false', dest='verbose',
                               help="Don't write error messages to stdout")
    parent_parser.add_argument('--no-header', action='store_false', dest='write_header',
                               help='Do not write the header to the log files when starting.')
    parent_parser.add_argument('-b', '--backup-bad-output-dir', default='/tmp',
                               help='Directory where the backup outputs will be saved.')

    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers(dest='command')

    monitor_parser = subparsers.add_parser('monitor', parents=[parent_parser])
    monitor_parser.add_argument('-p', '--pid', type=int, help='Pid of the process to monitor for CPU&GPU usage.')

    launch_parser = subparsers.add_parser('launch', parents=[parent_parser])
    launch_parser.add_argument('-o', '--output', dest='stdout', default='-', help='Subprocess stdout')
    launch_parser.add_argument('-e', '--error', dest='stderr', default='-', help='Subprocess stderr')
    launch_parser.add_argument('-I', '--input', dest='stdin', default='-', help='Subprocess stdin')
    launch_parser.add_argument('--keep-alive', action='store_true', help='Keep running task when monitor process exits')
    launch_parser.add_argument('cmdline', nargs='+', metavar='CMD', help='The command to launch and monitor.')

    return parser


def monitor(args):
    if args.pid is not None and args.gpu is None and args.cpu_and_ram is None and args.verbose:
        sys.stderr.write('Monitoring pid {} but neither --gpu nor --cpu-and-ram options provided'.format(args.pid))
    run(
        interval=args.interval,
        gpu=args.gpu,
        temperatures=args.temperatures,
        cpu_and_ram=args.cpu_and_ram,
        pid=args.pid,
        write_header=args.write_header,
        backup_bad_output_dir=args.backup_bad_output_dir,
    )


@contextmanager
def name_of_temporary_file(verbose=False):
    # best-effort to remove the temporary file when we are done
    fd, tmp_filename = tempfile.mkstemp(suffix='.heimdallr')
    os.close(fd)
    try:
        yield tmp_filename
    finally:
        try:
            os.remove(tmp_filename)
        except Exception as e:
            if verbose:
                msg = "Failed to delete temporary file {0}.\n{1.__class__.__name__}: {1}"
                sys.stderr.write(msg.format(tmp_filename, e))


def _run_subprocess(cmdline, in_filename, out_filename, err_filename, preexec_fn=lambda: None):
    in_filename = argparse.FileType('rb')(in_filename)
    outer = argparse.FileType('wb')
    return subprocess.Popen(
        cmdline,
        stdin=in_filename,
        stdout=outer(out_filename),
        stderr=outer(err_filename),
        preexec_fn=preexec_fn
    )


def _middle_process(tmp_filename, args):
    # setsid needed to make sure we don't get killed when our parent dies.
    os.setsid()
    os.umask(0)
    # spawn the background task
    proc = _run_subprocess(args.cmdline, args.stdin, args.stdout, args.stderr)
    proc_pid = proc.pid
    # store the pid of the background task in the temporary file
    with open(tmp_filename, 'wb') as f:
        f.write(str(proc_pid).encode('ascii') + b'\n')
    # quit this process immediately. No cleanup (the file above should have already flushed everything.
    os._exit(0)


def launch(args):
    """Spawns a background process and then monitors it.

    If `args.keep_alive` is `True`, then it ensures that the background task is not killed when this process exits,
    while if `args.keep_alive` is `False` it ensures that the background task is killed when this process exits.

    """
    if args.keep_alive:
        try:
            # make sure that monitor can be killed without killing the background task
            # to achieve this we have to fork twice, so that the background task gets inherited by
            # the process 1 (either init or systemd or whatever).
            # We need its pid so we create a temporary file where the middle-process writes the task's pid.
            with name_of_temporary_file(args.verbose) as tmp_filename:
                cpid = os.fork()
                if cpid == 0:
                    # we are the child process
                    _middle_process(tmp_filename, args)
                else:
                    # we are the original Heimdallr process. Wait for the middle process to die
                    os.waitpid(cpid, 0)
                    # get the pid of the background process we have to monitor.
                    with open(tmp_filename) as pid_file:
                        args.pid = int(pid_file.read())
                        if args.verbose:
                            sys.stderr.write('Background task has PID: {}\n'.format(args.pid))
        except Exception as e:
            if hasattr(args, 'pid'):
                # probably an issue with deleting the temporary file?
                sys.stderr.write('Error after starting background task.\n{0.__class__.__name__}: {0}'.format(e))
            else:
                msg = (
                    "Error during or after starting the background task. It may or may not have started successfully.\n"
                    "{0.__class__.__name__}: {0}\n"
                )
                sys.stderr.write(msg.format(e))
                sys.exit(1)
    else:
        # in this case we want to ensure that the background task gets killed with us.
        # we register an atexit function that kills it, first via SIGTERM and after 5 seconds SIGKILL.
        proc = _run_subprocess(args.cmdline, args.stdin, args.stdout, args.stderr, preexec_fn=os.setsid)
        args.pid = proc.pid
        kill_gently = create_gentle_killer(proc, args.verbose)
        victim_id = os.getpgid(proc.pid)
        atexit.register(kill_gently, victim_id)
        signal.signal(signal.SIGTERM, lambda _: kill_gently(victim_id))
        signal.signal(signal.SIGABRT, lambda _: kill_gently(victim_id))

    monitor(args)


def create_gentle_killer(proc, verbose):
    """Returns a function that will try to kill the given process and corresponding process group."""
    proc_pid = proc.pid
    if verbose:
        log = sys.stderr.write
    else:
        def log(_):
            """noop"""

    def kill_gently(victim_id):
        """Kills the process group `victim_id` and then terminates the current process with exit code 1."""
        # try with SIGTERM
        try:
            log("Killing background task gently. ")
            try:
                os.killpg(victim_id, signal.SIGTERM)
                if proc.poll() is None:
                    log("Waiting up to 5 seconds ")
                    for i in range(25):
                        time.sleep(0.2)
                        if i % 5 == 0:
                            log('.')
                        if proc.poll() is not None:
                            log(' Process completed.\n')
                            break
                else:
                    log("Task killed.\n")
            except Exception as e:
                log("got an exception: {0.__class__.__name__}: {0}\n".format(e))

            if proc.poll() is None:
                # stop being gentle. Go with SIGKILL
                log("killing background task BRUTALLY...")
                try:
                    os.killpg(victim_id, signal.SIGKILL)
                    log("Task brutally killed.\n")
                except Exception as e:
                    msg = (
                        "got an exception: {0.__class__.__name__}: {0}\n"
                        "The background task with pid: {1} might still be alive!\n"
                    )
                    log(msg.format(e, proc_pid))
        finally:
            log('Exiting main process.\n')
            sys.exit(1)

    return kill_gently


def main():
    parser = _make_parser()
    args = parser.parse_args()
    if args.command == 'launch':
        launch(args)
    elif args.command == 'monitor':
        monitor(args)
    else:
        parser.error('You must select a sub-command to run.')



if __name__ == '__main__':
    main()
